{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Terrorist Attacks\n",
    "## Objective\n",
    "To build a classifier that can predict the group responsible for individual terrorist attacks around the world.\n",
    "## Introduction\n",
    "The classifier is trained using the [Global Terrorism Database (GTD)](http://apps.start.umd.edu/gtd/downloads/dataset/Codebook.pdf). The dataset consists of nearly 200,000 terrorist attacks including bombings, assassinations, and kidnappings that have occured since 1970. Each of these attacks includes information on over 45 variables including location, type of weapon used, and nationality of the perpetrator.\n",
    "\n",
    "This classifer is focused on using information about an attack to predict the responsible group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "Before training, the data must be prepared by selecting certain features to remove or augment. The following features from the dataset are kept (reference the [GTD](http://apps.start.umd.edu/gtd/downloads/dataset/Codebook.pdf) for more information on each feature):\n",
    "- <b>Numerical Features (Bucketized)</b><br/>\n",
    "nkill, nkillus, nkillter, nwound, nwoundus, nperps\n",
    "\n",
    "- <b>Categorical Features</b><br/>\n",
    "crit1, crit2, crit3, attacktype1, attacktype2, attacktype3, weaptype1, weapsubtype1, weaptype2, weapsubtype2, weaptype3, weapsubtype3, weaptype4, weapsubtype4, natlty1, natlty2, natlty3, targtype1, targtype2, targtype3, claimed, doubtterr, country, multiple, success, suicide<br/>\n",
    "\n",
    "- <b>Label</b><br/>\n",
    "gnome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make necessary imports\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variables\n",
    "columns_to_use = ['country', 'crit1', 'crit2', 'crit3', 'doubtterr', 'multiple', 'success', 'suicide', 'attacktype1', 'attacktype2', 'attacktype3', 'targtype1', 'natlty1', 'targtype2', 'natlty2', 'targtype3', 'natlty3', 'nperps', 'claimed', 'weaptype1', 'weapsubtype1', 'weaptype2', 'weapsubtype2', 'weaptype3', 'weapsubtype3', 'weaptype4', 'weapsubtype4', 'nkill', 'nkillus', 'nkillter', 'nwound', 'nwoundus', 'gname']\n",
    "input_file = 'data/gtd1993_0617dist.xlsx'\n",
    "csv_file = 'data/gtd1993_0617dist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the excel data file to a csv\n",
    "wb = xlrd.open_workbook(input_file)\n",
    "sh = wb.sheets()[0]\n",
    "output_csv = open(csv_file, 'w')\n",
    "wr = csv.writer(output_csv, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "for rownum in range(sh.nrows):\n",
    "\twr.writerow(sh.row_values(rownum))\n",
    "\n",
    "output_csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Deep Neural Network\n",
    "Now the neural network must be constructed. It is a deep neural network that uses a mix of numerical, bucketized columns and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the numerical columns\n",
    "num_killed = tf.feature_column.numeric_column(key='nkill')\n",
    "num_wounded = tf.feature_column.numeric_column(key='nwound')\n",
    "num_us_killed = tf.feature_column.numeric_column(key='nkillus')\n",
    "num_us_wounded = tf.feature_column.numeric_column(key='nwoundus')\n",
    "num_perps = tf.feature_column.numeric_column(key='nperps')\n",
    "num_perps_killed = tf.feature_column.numeric_column(key='nkillter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucketize each of the numerical columns\n",
    "num_killed = tf.feature_column.bucketized_column(source_column=num_killed, boundaries=[5, 25, 50])\n",
    "num_wounded = tf.feature_column.bucketized_column(source_column=num_wounded, boundaries=[5, 25, 50])\n",
    "num_us_killed = tf.feature_column.bucketized_column(source_column=num_us_killed, boundaries=[5, 25, 50])\n",
    "num_us_wounded = tf.feature_column.bucketized_column(source_column=num_us_wounded, boundaries=[5, 25, 50])\n",
    "num_perps = tf.feature_column.bucketized_column(source_column=num_perps, boundaries=[1, 3])\n",
    "num_perp_killed = tf.feature_column.bucketized_column(source_column=num_perps_killed, boundaries=[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the categorical columns\n",
    "terror_criteria1 = tf.feature_column.categorical_column_with_identity(key='crit1', num_buckets=2)\n",
    "terror_criteria2 = tf.feature_column.categorical_column_with_identity(key='crit2', num_buckets=2)\n",
    "terror_criteria3 = tf.feature_column.categorical_column_with_identity(key='crit3', num_buckets=2)\n",
    "attack_type1 = tf.feature_column.categorical_column_with_identity(key='attacktype1', num_buckets=9)\n",
    "attack_type2 = tf.feature_column.categorical_column_with_identity(key='attacktype2', num_buckets=9)\n",
    "attack_type3 = tf.feature_column.categorical_column_with_identity(key='attacktype3', num_buckets=9)\n",
    "weapon_type1 = tf.feature_column.categorical_column_with_identity(key='weaptype1', num_buckets=13)\n",
    "weapon_subtype1 = tf.feature_column.categorical_column_with_identity(key='weapsubtype1', num_buckets=30)\n",
    "weapon_type2 = tf.feature_column.categorical_column_with_identity(key='weaptype2', num_buckets=13)\n",
    "weapon_subtype2 = tf.feature_column.categorical_column_with_identity(key='weapsubtype2', num_buckets=30)\n",
    "weapon_type3 = tf.feature_column.categorical_column_with_identity(key='weaptype3', num_buckets=13)\n",
    "weapon_subtype3 = tf.feature_column.categorical_column_with_identity(key='weapsubtype3', num_buckets=30)\n",
    "weapon_type4 = tf.feature_column.categorical_column_with_identity(key='weaptype4', num_buckets=13)\n",
    "weapon_subtype4 = tf.feature_column.categorical_column_with_identity(key='weapsubtype4', num_buckets=30)\n",
    "target_nationality1 = tf.feature_column.categorical_column_with_identity(key='natlty1', num_buckets=10004)\n",
    "target_nationality2 = tf.feature_column.categorical_column_with_identity(key='natlty2', num_buckets=10004)\n",
    "target_nationality3 = tf.feature_column.categorical_column_with_identity(key='natlty3', num_buckets=10004)\n",
    "target_type1 = tf.feature_column.categorical_column_with_identity(key='targtype1', num_buckets=22)\n",
    "target_type2 = tf.feature_column.categorical_column_with_identity(key='targtype2', num_buckets=22)\n",
    "target_type3 = tf.feature_column.categorical_column_with_identity(key='targtype3', num_buckets=22)\n",
    "responsibility_claimed = tf.feature_column.categorical_column_with_identity(key='claimed', num_buckets=2)\n",
    "terrorism_doubt = tf.feature_column.categorical_column_with_identity(key='doubtterr', num_buckets=2)\n",
    "country_occurred = tf.feature_column.categorical_column_with_identity(key='country', num_buckets=1004)\n",
    "multiple_incidents = tf.feature_column.categorical_column_with_identity(key='multiple', num_buckets=2)\n",
    "was_successful = tf.feature_column.categorical_column_with_identity(key='success', num_buckets=2)\n",
    "was_suicide = tf.feature_column.categorical_column_with_identity(key='suicide', num_buckets=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each of the categorical columns to indicator functions\n",
    "terror_criteria1 = tf.feature_column.indicator_column(terror_criteria1)\n",
    "terror_criteria2 = tf.feature_column.indicator_column(terror_criteria2)\n",
    "terror_criteria3 = tf.feature_column.indicator_column(terror_criteria3)\n",
    "attack_type1 = tf.feature_column.indicator_column(attack_type1)\n",
    "attack_type2 = tf.feature_column.indicator_column(attack_type2)\n",
    "attack_type3 = tf.feature_column.indicator_column(attack_type3)\n",
    "weapon_type1 = tf.feature_column.indicator_column(weapon_type1)\n",
    "weapon_subtype1 = tf.feature_column.indicator_column(weapon_subtype1)\n",
    "weapon_type2 = tf.feature_column.indicator_column(weapon_type2)\n",
    "weapon_subtype2 = tf.feature_column.indicator_column(weapon_subtype2)\n",
    "weapon_type3 = tf.feature_column.indicator_column(weapon_type3)\n",
    "weapon_subtype3 = tf.feature_column.indicator_column(weapon_subtype3)\n",
    "weapon_type4 = tf.feature_column.indicator_column(weapon_type4)\n",
    "weapon_subtype4 = tf.feature_column.indicator_column(weapon_subtype4)\n",
    "target_nationality1 = tf.feature_column.indicator_column(target_nationality1)\n",
    "target_nationality2 = tf.feature_column.indicator_column(target_nationality2)\n",
    "target_nationality3 = tf.feature_column.indicator_column(target_nationality3)\n",
    "target_type1 = tf.feature_column.indicator_column(target_type1)\n",
    "target_type2 = tf.feature_column.indicator_column(target_type2)\n",
    "target_type3 = tf.feature_column.indicator_column(target_type3)\n",
    "responsibility_claimed = tf.feature_column.indicator_column(responsibility_claimed)\n",
    "terrorism_doubt = tf.feature_column.indicator_column(terrorism_doubt)\n",
    "country_occurred = tf.feature_column.indicator_column(country_occurred)\n",
    "multiple_incidents = tf.feature_column.indicator_column(multiple_incidents)\n",
    "was_successful = tf.feature_column.indicator_column(was_successful)\n",
    "was_suicide = tf.feature_column.indicator_column(was_suicide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a list of each of the deep columns\n",
    "deep_columns = [\n",
    "\tnum_killed,\n",
    "\tnum_us_killed,\n",
    "\tnum_us_wounded,\n",
    "\tnum_perps,\n",
    "\tnum_perp_killed,\n",
    "\tterror_criteria1,\n",
    "\tterror_criteria2,\n",
    "\tterror_criteria3,\n",
    "\tattack_type1,\n",
    "\tattack_type2,\n",
    "\tattack_type3,\n",
    "\tweapon_type1,\n",
    "\tweapon_subtype1,\n",
    "\tweapon_type2,\n",
    "\tweapon_subtype2,\n",
    "\tweapon_type3,\n",
    "\tweapon_subtype3,\n",
    "\tweapon_type4,\n",
    "\tweapon_subtype4,\n",
    "\ttarget_nationality1,\n",
    "\ttarget_nationality2,\n",
    "\ttarget_nationality3,\n",
    "\ttarget_type1,\n",
    "\ttarget_type2,\n",
    "\ttarget_type3,\n",
    "\tresponsibility_claimed,\n",
    "\tterrorism_doubt,\n",
    "\tcountry_occurred,\n",
    "\tmultiple_incidents,\n",
    "\twas_successful,\n",
    "\twas_suicide\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the DNN\n",
    "dnn = tf.estimator.DNNClassifier(\n",
    "\tn_classes=100,\n",
    "\tfeature_columns=deep_columns,\n",
    "\thidden_units=[100, 50],\n",
    "\tactivation_fn=\"relu\",\n",
    "\tdropout=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "Now the network must be trained on the GTD data from 1993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(y_name):\n",
    "\ttrain = pd.read_csv(csv_file, usecols=columns_to_use)\n",
    "\ttrain_x, train_y = train, train.pop(y_name)\n",
    "\t\n",
    "\ttrain_x.fillna(-1, inplace=True)\n",
    "\t\n",
    "\t\n",
    "\ttrain_final_x = {}\n",
    "\t\n",
    "\tfor n in train_x:\n",
    "\t\ttrain_x[n] = train_x[n].astype(int)\n",
    "\t\ttrain_final_x[n] = tf.convert_to_tensor(train_x[n])\n",
    "\t\t\n",
    "\treturn train_final_x, tf.convert_to_tensor(train_y)\n",
    "\t\n",
    "dnn.train(input_fn=lambda: load_data('gname'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- K-fold splitting of the data\n",
    "- Testing out which epoch and batch sizes are optimal\n",
    "- Graph accuracy over epoch count of training set and test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
